{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 13:12:46.152820: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747761166.214507    9357 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747761166.232473    9357 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747761166.362177    9357 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747761166.362196    9357 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747761166.362199    9357 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747761166.362200    9357 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-20 13:12:46.375693: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import datetime\n",
    "import tensorflow                       as tf\n",
    "from tensorflow.keras.callbacks         import TensorBoard\n",
    "from tensorflow.keras.layers            import Input, Lambda,UpSampling2D, Conv2D,Dropout,MaxPooling2D,Conv2DTranspose,concatenate,BatchNormalization, Activation\n",
    "from tensorflow.keras.models            import Model\n",
    "from tensorflow.keras.optimizers        import Adam,RMSprop\n",
    "from keras.utils                        import plot_model\n",
    "from tensorflow.keras                   import layers, models\n",
    "from tensorflow.keras.losses            import mae\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import random, time\n",
    "from pathlib                        import Path\n",
    "from PIL                            import Image\n",
    "\n",
    "import skimage                      as ski\n",
    "from   skimage.filters              import threshold_otsu\n",
    "from   skimage                      import io, color\n",
    "from   skimage.color                import rgb2gray\n",
    "from   skimage                      import filters\n",
    "import cv2                          as cv\n",
    "import matplotlib.pyplot            as plt \n",
    "import gc\n",
    "import glob\n",
    "from skimage                        import img_as_ubyte\n",
    "from skimage                        import io\n",
    "import shutil\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">1. Processing data</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"red\">1.1. Selecting a Sample</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_path_data = '/home/ppgi/Trabajo/Codigos_generate_data/DLCODES-VER-5'\n",
    "\n",
    "subdirectories = ['/Geometry','/Magnitude','/Pression','/U001','/U002']\n",
    "\n",
    "geo_path =  general_path_data + subdirectories[0]\n",
    "v_path   =  general_path_data + subdirectories[1]\n",
    "p_path   =  general_path_data + subdirectories[2]\n",
    "vx_path  =  general_path_data + subdirectories[3]\n",
    "vy_path  =  general_path_data + subdirectories[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for reading image    \n",
    "def get_img(img_name):\n",
    "    return ski.io.imread(img_name)\n",
    "\n",
    "def resizing_img(x,new_width=200):\n",
    "   \n",
    "    height=x.shape[0]\n",
    "    width=x.shape[1]\n",
    "    ratio = height / width\n",
    "    new_height = int(new_width * ratio)\n",
    "    y =cv.resize(x,(new_width,new_height))\n",
    "    return y\n",
    "\n",
    "# method for turning to a grey or binary image \n",
    "def processing(image,option):\n",
    "        x = get_img(image)  \n",
    "        x = rgb2gray(x)               # It returns a grayscale image with floating point values in the range from 0 to 1\n",
    "        y = resizing_img(x) # Reshape image \n",
    "    \n",
    "        # Binary option otherwise gray\n",
    "        if (option):\n",
    "            y=ski.util.img_as_ubyte(y)  # Convert it back to the original data type and the data range back 0 to 255. \n",
    "                                        # It is often better to use image values represented by floating point values \n",
    "            best_value_threshold=np.round(filters.threshold_otsu(y)) #  Otsu’s method calculates an “optimal” threshold\n",
    "\n",
    "            _,y= cv.threshold(y, best_value_threshold, 255, cv.THRESH_BINARY)\n",
    "            y=y/255.\n",
    "        y=y[:, :, np.newaxis]\n",
    "        return y\n",
    "\n",
    "def create_file(path,name='Images_masked'):\n",
    "     newpath = path +'/' +name\n",
    "     os.makedirs(newpath, exist_ok=True)\n",
    "     return newpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "#newpath = '/home/ppgi/Trabajo/Codigos_generate_data/DLCODES-VER-5/Pression/p_00020.png'\n",
    "'/home/ppgi/Trabajo/predicting-flow-patterns/Images_masked'\n",
    "'/home/ppgi/Trabajo/predicting-flow-patterns/Images_masked/npy_pression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_npy(path_origin,name_sub_file,option,n_sample = 1000):\n",
    "    images = sorted([os.path.join(path_origin,fname) for fname in os.listdir(path_origin) if fname.endswith(\".png\")])\n",
    "    current_path = os.getcwd() \n",
    "    if (n_sample <= 20000):\n",
    "\n",
    "        I = images[1:n_sample+1]\n",
    "        newpath1=create_file(current_path)\n",
    "        new_root = newpath1 +'/' +name_sub_file\n",
    "        os.makedirs(new_root, exist_ok=True)\n",
    "   \n",
    "        for img in I:\n",
    "            name_img = os.path.splitext(os.path.basename(img))[0]\n",
    "            save_in=new_root+'/'+ name_img+'.npy'\n",
    "            print(save_in)\n",
    "            x=processing(img,option)\n",
    "            np.save(save_in,x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(path1,path2,save_in):\n",
    "    path_1 = Path(path1)\n",
    "    file_npy_1=sorted(list(path_1.glob('*.npy')))\n",
    "    \n",
    "    path_2 = Path(path2)\n",
    "    file_npy_2=sorted(list(path_2.glob('*.npy')))\n",
    "\n",
    "    for f1, f2 in zip(file_npy_1,file_npy_2):\n",
    "            array_1 = np.load(f1)\n",
    "            array_2 = np.load(f2)\n",
    "            array_masked=array_1*array_2\n",
    "            np.save(save_in,array_masked)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_masked():\n",
    "    path =  os.getcwd() \n",
    "    path= create_file(path,name='Final_mask'):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask each image\n",
    "def mask (name_file,name_data,path_file_1,path_file_2=None):\n",
    "    print('enter')\n",
    "    if path_file_2 == None:\n",
    "        path_1 = Path(path_file_1)\n",
    "        file_npy_1=sorted(list(path_1.glob('*.npy')))\n",
    "        current_directory = Path.cwd()\n",
    "        save_in = str(current_directory) + '/' + name_file \n",
    "        os.makedirs(save_in, exist_ok=True)\n",
    "        n = 1\n",
    "        for f1 in file_npy_1:\n",
    "            array_1 = np.load(f1)\n",
    "            save= save_in+ '/'+name_data+f'_{n:05d}.png'\n",
    "            array_2d = img_as_ubyte(array_1.squeeze())\n",
    "            io.imsave(save, array_2d)\n",
    "            n=n+1\n",
    "    else:\n",
    "        path_1 = Path(path_file_1)\n",
    "        path_2 = Path(path_file_2)\n",
    "        file_npy_1=sorted(list(path_1.glob('*.npy')))\n",
    "        file_npy_2=sorted(list(path_2.glob('*.npy')))\n",
    "        current_directory = Path.cwd()\n",
    "        save_in = str(current_directory) + '/' + name_file \n",
    "        os.makedirs(save_in, exist_ok=True)\n",
    "        n = 1 \n",
    "        for f1, f2 in zip(file_npy_1,file_npy_2):\n",
    "            array_1 = np.load(f1)\n",
    "            array_2 = np.load(f2)\n",
    "            array_masked=array_1*array_2\n",
    "            save= save_in+ '/'+name_data+f'_{n:05d}.png'\n",
    "            array_2d = img_as_ubyte(array_masked.squeeze())\n",
    "            io.imsave(save, array_2d)\n",
    "            n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_00001\n",
      "/home/ppgi/Trabajo/predicting-flow-patterns/Images_masked/prueba2/p_00001.npy\n",
      "p_00002\n",
      "/home/ppgi/Trabajo/predicting-flow-patterns/Images_masked/prueba2/p_00002.npy\n",
      "p_00003\n",
      "/home/ppgi/Trabajo/predicting-flow-patterns/Images_masked/prueba2/p_00003.npy\n",
      "p_00004\n",
      "/home/ppgi/Trabajo/predicting-flow-patterns/Images_masked/prueba2/p_00004.npy\n",
      "p_00005\n",
      "/home/ppgi/Trabajo/predicting-flow-patterns/Images_masked/prueba2/p_00005.npy\n",
      "p_00006\n",
      "/home/ppgi/Trabajo/predicting-flow-patterns/Images_masked/prueba2/p_00006.npy\n",
      "p_00007\n",
      "/home/ppgi/Trabajo/predicting-flow-patterns/Images_masked/prueba2/p_00007.npy\n",
      "p_00008\n",
      "/home/ppgi/Trabajo/predicting-flow-patterns/Images_masked/prueba2/p_00008.npy\n",
      "p_00009\n",
      "/home/ppgi/Trabajo/predicting-flow-patterns/Images_masked/prueba2/p_00009.npy\n",
      "p_00010\n",
      "/home/ppgi/Trabajo/predicting-flow-patterns/Images_masked/prueba2/p_00010.npy\n"
     ]
    }
   ],
   "source": [
    "create_npy(p_path,'prueba2',False,n_sample = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_npy(p_path,'prueba',False,n_sample = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newEnviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
