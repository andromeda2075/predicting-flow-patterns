{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import datetime\n",
    "import tensorflow                       as tf\n",
    "from tensorflow.keras.callbacks         import TensorBoard\n",
    "from tensorflow.keras.layers            import Input, Lambda,UpSampling2D, Conv2D,Dropout,MaxPooling2D,Conv2DTranspose,concatenate,BatchNormalization, Activation\n",
    "from tensorflow.keras.models            import Model\n",
    "from tensorflow.keras.optimizers        import Adam,RMSprop\n",
    "from keras.utils                        import plot_model\n",
    "from tensorflow.keras                   import layers, models\n",
    "from tensorflow.keras.losses            import mae\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import random, time\n",
    "from pathlib                        import Path\n",
    "from PIL                            import Image\n",
    "\n",
    "import skimage                      as ski\n",
    "from   skimage.filters              import threshold_otsu\n",
    "from   skimage                      import io, color\n",
    "from   skimage.color                import rgb2gray\n",
    "from   skimage                      import filters\n",
    "import cv2                          as cv\n",
    "import matplotlib.pyplot            as plt \n",
    "import gc\n",
    "import glob\n",
    "from skimage                        import img_as_ubyte\n",
    "from skimage                        import io\n",
    "import shutil\n",
    "import pandas as pd\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"red\">1. Load dataset</font>\n",
    "\n",
    "Load NumPy arrays with tf.data.Dataset. Passing the two arrays as a tuple into tf.data.Dataset.from_tensor_slices to create a tf.data.Dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_directory = '/home/ppgi/Trabajo/predicting-flow-patterns/V_Masked'\n",
    "\n",
    "path_train ='/home/ppgi/Trabajo/predicting-flow-patterns/V_Masked/train'\n",
    "path_test ='/home/ppgi/Trabajo/predicting-flow-patterns/V_Masked/test'\n",
    "path_val= '/home/ppgi/Trabajo/predicting-flow-patterns/V_Masked/valid'\n",
    "\n",
    "nbatch = 10\n",
    "\n",
    "def dataset_array(flow_path,geo_path):\n",
    "    def load_array(flow,geo):\n",
    "        x = np.load(flow)\n",
    "        y = np.load(geo)\n",
    "        return x,y\n",
    "\n",
    "    x, y = tf.numpy_function(load_array, [flow_path, geo_path], [tf.float64, tf.float64])\n",
    "    x.set_shape([x.shape[0],x.shape[1],x.shape[2]])\n",
    "    y.set_shape([y.shape[0],y.shape[1],y.shape[2]])\n",
    "    return x,y\n",
    "\n",
    "def create_dataset(flow_path,geo_path,batch_size = nbatch):\n",
    "    x_files = sorted(glob.glob(os.path.join(flow_path, \"*.npy\")))\n",
    "    y_files = sorted(glob.glob(os.path.join(geo_path, \"*.npy\")))\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_files, y_files))\n",
    "    dataset = dataset.map(dataset_array, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_path_train='/home/ppgi/Trabajo/predicting-flow-patterns/G_Masked/train'\n",
    "p_path_train='/home/ppgi/Trabajo/predicting-flow-patterns/V_Masked/train'\n",
    "\n",
    "geo_path_valid='/home/ppgi/Trabajo/predicting-flow-patterns/G_Masked/valid'\n",
    "p_path_valid='/home/ppgi/Trabajo/predicting-flow-patterns/V_Masked/valid'\n",
    "\n",
    "geo_path_test='/home/ppgi/Trabajo/predicting-flow-patterns/G_Masked/test'\n",
    "p_path_test='/home/ppgi/Trabajo/predicting-flow-patterns/V_Masked/test'\n",
    "\n",
    "train_ds =create_dataset(geo_path_train,p_path_train)\n",
    "test_ds  =create_dataset(geo_path_test,p_path_test)\n",
    "valid_ds =create_dataset(geo_path_valid,p_path_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"red\">3. Hiperparameters</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs    =30\n",
    "patience      =15       # How long to wait after last time validation loss improved\n",
    "LR            =0.0001\n",
    "\n",
    "# Model name\n",
    "model_name    =\"U-Net\"\n",
    "save_in       ='/home/ppgi/Trabajo/predicting-flow-patterns'\n",
    "\n",
    "# image dimensions\n",
    "img_width     =  256   # 739   G:737\n",
    "img_height    =  64   # 185\n",
    "channel       =  1\n",
    "\n",
    "#number_of_filters = [64, 128, 256, 512, 1024]\n",
    "number_of_filters = [32,64,128,256,512]\n",
    "\n",
    "type_padding = 'same'\n",
    "f_activation = 'relu'\n",
    "f_activation_last='relu'\n",
    "#optimizer = RMSprop(learning_rate=LR)\n",
    "optimizer = Adam(learning_rate=LR)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',  min_delta=1e-2, patience=patience, restore_best_weights=True,verbose=1)\n",
    "save = save_in + '/Results_weights/Best_weights.weights.h5'\n",
    "checkpoint_cb=tf.keras.callbacks.ModelCheckpoint(save,save_weights_only=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"red\">4. Architecture</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block_batchnorm(filters,x):\n",
    "    conv = Conv2D(filters, (3, 3), padding=type_padding)(x)\n",
    "    conv= BatchNormalization()(conv)\n",
    "    conv = Activation(f_activation)(conv)\n",
    "    conv = Conv2D(filters, (3, 3), padding=type_padding)(conv)\n",
    "    conv= BatchNormalization()(conv)\n",
    "    conv = Activation(f_activation)(conv)\n",
    "    return conv\n",
    "    \n",
    "def conv_block(filters,x):\n",
    "    conv = Conv2D(filters, (3, 3), activation=f_activation, padding=type_padding)(x)\n",
    "    conv = Conv2D(filters, (3, 3), activation=f_activation, padding=type_padding)(conv)\n",
    "    return conv    \n",
    "\n",
    "def encoder(x,filters):\n",
    "    conv = conv_block_batchnorm(filters,x)\n",
    "    downsample = MaxPooling2D((2,2))(conv)\n",
    "    return conv,downsample\n",
    "\n",
    "def decoder(x1,x2,filters,transpose=None):\n",
    "    if transpose != None:\n",
    "        conv_up = Conv2DTranspose(filters,(2,2),strides=(2, 2),padding=type_padding)(x1)\n",
    "    else:\n",
    "        conv_up = UpSampling2D((2, 2))(x1)\n",
    "   \n",
    "    concat=concatenate([conv_up,x2],axis = 3)\n",
    "    up = conv_block(filters, concat)\n",
    "    return up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### <font color=\"red\">4.1 U-Net </font>\n",
    "Building  u-net arquitecture with one decoder i.e. only pression as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_of_filters = [32,64,128,256,512]\n",
    "def make_model():\n",
    "    \n",
    "    image_input = Input((img_height, img_width, channel))\n",
    "    \n",
    "    conv1,down_block1 = encoder (image_input, number_of_filters[0])\n",
    "    conv2,down_block2 = encoder (down_block1 , number_of_filters[1])\n",
    "    conv3,down_block3 = encoder (down_block2 , number_of_filters[2])\n",
    "    conv4,down_block4 = encoder (down_block3 , number_of_filters[3])\n",
    "\n",
    "    conv5 = conv_block(number_of_filters[4],down_block4)\n",
    "\n",
    "    up6=decoder(conv5,conv4,number_of_filters[3],transpose='yes')\n",
    "    up7=decoder(up6,conv3,number_of_filters[2],transpose='yes')\n",
    "    up8=decoder(up7,conv2,number_of_filters[1],transpose='yes')\n",
    "    up9=decoder(up8,conv1,number_of_filters[0],transpose='yes')\n",
    "\n",
    "    p_out = Conv2D(1, (1, 1), activation=f_activation_last,name='p_output',padding=\"same\")(up9)\n",
    "\n",
    "    # construct model\n",
    "    model =  keras.Model(inputs=image_input, outputs=[p_out],name= model_name)\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer=optimizer, \n",
    "              loss = 'mean_squared_error',\n",
    "              \n",
    "              metrics= ['mae'] )\n",
    "\n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=make_model()\n",
    "#tf.keras.utils.plot_model(M, show_shapes=True, expand_nested=True, dpi=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### <font color=\"red\">4.2 Fitting</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting trainig\")\n",
    "\n",
    "history = M.fit(train_ds,epochs=num_epochs,validation_data = valid_ds,callbacks=[early_stopping,checkpoint_cb])\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(\"Unet.keras\",save_best_only=True)]\n",
    "M.save('Completed_Model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=\"red\">4.3 Evaluation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = M.evaluate(test_ds) \n",
    "print(\"Evaluation results:\")\n",
    "for name, value in zip(M.metrics_names, results):\n",
    "    print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=\"red\">4.4 Prediction</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrue=[]\n",
    "ytrue=[]\n",
    "for x,y in test_ds:\n",
    "    xtrue.append(x.numpy())\n",
    "    ytrue.append(y.numpy())\n",
    "\n",
    "ypred = list()\n",
    "for i in range(nbatch):\n",
    "        ypred.append(M.predict(xtrue[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=\"red\">4.5 Visualization of flow predicted</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 2, figsize=(16, 12))\n",
    "titles = [ 'P pred', 'P true','V pred', 'V true','Vx pred', 'Vx true','Vy pred', 'Vy true']\n",
    "for i in range(nbatch):\n",
    "    N = random.randint(0, nbatch-1)\n",
    "    title = titles[2:4]\n",
    "    axes[i, 0].imshow(ypred[i][N], cmap='gray'); axes[i, 0].set_title(f'{title[0]} - batch {i}-{N}')\n",
    "    axes[i, 1].imshow(ytrue[i][N], cmap='gray'); axes[i, 1].set_title(f'{title[1]}- batch {i}-{N}')\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.axis('off')    \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=\"red\">4.6 Training and Validation plots</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[['loss', 'val_loss']].plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[['mae', 'val_mae']].plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.show()  \n",
    "fig.savefig(\"Output V.png\", dpi=300, bbox_inches='tight')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
