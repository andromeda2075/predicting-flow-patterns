{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7661eb65-7254-453f-98f0-11f25f94ae7e",
   "metadata": {},
   "source": [
    "### 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51e0157a-1a6a-4a13-a098-01f23adca71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 17:29:35.732585: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746048575.806144   24525 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746048575.825875   24525 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746048575.977899   24525 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746048575.977925   24525 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746048575.977926   24525 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746048575.977928   24525 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-30 17:29:35.996016: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import datetime\n",
    "import tensorflow                       as tf\n",
    "from tensorflow.keras.callbacks         import TensorBoard\n",
    "from tensorflow.keras.layers            import Input, Lambda, Conv2D,Dropout,MaxPooling2D,Conv2DTranspose,concatenate,BatchNormalization, Activation\n",
    "from tensorflow.keras.models            import Model\n",
    "from tensorflow.keras.optimizers        import Adam\n",
    "from keras.utils                        import plot_model\n",
    "from tensorflow.keras                   import layers, models\n",
    "from tensorflow.keras.losses            import mae\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import random, time\n",
    "from pathlib                            import Path\n",
    "\n",
    "import skimage                      as ski\n",
    "from   skimage.filters              import threshold_otsu\n",
    "from   skimage                      import io, color\n",
    "from   skimage.color                import rgb2gray\n",
    "from   skimage                      import filters\n",
    "import cv2                          as cv\n",
    "import matplotlib.pyplot            as plt \n",
    "import gc\n",
    "import glob\n",
    "import cupy as cp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f7c858-d131-4ed4-ae66-cab1b06eab5c",
   "metadata": {},
   "source": [
    "### 2. Load directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70a61cf8-3433-4f24-aa2e-6b29086f37f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main directory \n",
    "mainPath = \"/home/ppgi/Trabajo/Codigos_generate_data/DLCODES-VER-5\"\n",
    "#mainPath = \"/home/guiomar/Desktop/CODES/DLCODES-VER-5\"\n",
    "\n",
    "directory= os.path.abspath(mainPath)\n",
    "\n",
    "# Add directory to sys.path\n",
    "sys.path.append(directory)\n",
    "\n",
    "# import script where parameters are defined\n",
    "import param  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f07dae6-557d-4aab-9b90-5f5afcdd81fd",
   "metadata": {},
   "source": [
    "### 3. Defining parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96e16136-0e3c-44b5-b8be-8b572c2c5a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 => /home/ppgi/Trabajo/Codigos_generate_data/DLCODES-VER-5/Geometry\n",
      "1 => /home/ppgi/Trabajo/Codigos_generate_data/DLCODES-VER-5/Magnitude\n",
      "2 => /home/ppgi/Trabajo/Codigos_generate_data/DLCODES-VER-5/Pression\n",
      "3 => /home/ppgi/Trabajo/Codigos_generate_data/DLCODES-VER-5/U001\n",
      "4 => /home/ppgi/Trabajo/Codigos_generate_data/DLCODES-VER-5/U002\n",
      "\n",
      "Dimensions resized h = 128, w = 256\n",
      "Total data 20000\n"
     ]
    }
   ],
   "source": [
    "# Vizualizancing main directories \n",
    "list_of_paths = param.list_paths \n",
    "\n",
    "# Defining amount of train, test images   \n",
    "n_split=param.n_split\n",
    "\n",
    "# Defining a number of samples\n",
    "n_sample=param.n_sample\n",
    "\n",
    "# For resizing dimentions\n",
    "h=param.img_height\n",
    "w=param.img_width\n",
    "\n",
    "'''\n",
    "Showing parameters\n",
    "'''\n",
    "for i,j in enumerate(list_of_paths):\n",
    "    print(f'{i} => {j}')\n",
    "print(f'\\nDimensions resized h = {h}, w = {w}')\n",
    "print(f'Total data {n_sample}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becf6f0d-e6b1-4621-b083-00dee994440c",
   "metadata": {},
   "source": [
    "### 4. Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf2a15bb-9ae9-45ee-93ef-dab943b70331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for reading image    \n",
    "def get_img(img_name):\n",
    "    return ski.io.imread(img_name)\n",
    "\n",
    "# method for turning to a grey or binary image \n",
    "def processing(image,option=True):\n",
    "        x = get_img(image)  \n",
    "        x = rgb2gray(x)       # It returns a grayscale image with floating point values in the range from 0 to 1\n",
    "        x =cv.resize(x,(w,h)) # Reshape image \n",
    "    \n",
    "        # Binary option otherwise gray\n",
    "        if (option):\n",
    "            x=ski.util.img_as_ubyte(x)  # Convert it back to the original data type and the data range back 0 to 255. \n",
    "                                        # It is often better to use image values represented by floating point values \n",
    "            best_value_threshold=np.round(filters.threshold_otsu(x)) #  Otsu’s method calculates an “optimal” threshold\n",
    "\n",
    "            _,x= cv.threshold(x, best_value_threshold, 255, cv.THRESH_BINARY)\n",
    "            x=x/255.\n",
    "        x=x[:, :, np.newaxis]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7156231b-8af9-45be-aaf2-71469de69162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for processing by batches \n",
    "def  process_by_batches(list_of_paths,number_batch,name_file,option=True):\n",
    "    files=sorted([os.path.join(list_of_paths,fname) for fname in os.listdir(list_of_paths) if fname.endswith(\".png\")])\n",
    "    files=files[1:]\n",
    "    n_files=len(files)\n",
    "    new_file= param.save_in + '/' + name_file\n",
    "    os.makedirs(new_file, exist_ok=True)\n",
    "    for k,start in enumerate(range(0,n_files,number_batch)):\n",
    "         batch=[]\n",
    "         end = min(start + number_batch, n_files)\n",
    "         file_batches=files[start:end]\n",
    "         for img in file_batches:\n",
    "             x = processing(img,option)\n",
    "\n",
    "             # x = x * geo\n",
    "             \n",
    "             batch.append(x)  \n",
    "         print(k,'*************************')   \n",
    "         image_processed = new_file + f'/batch_images_{k:03d}.npy'\n",
    "         np.save(image_processed,batch,allow_pickle=True)   \n",
    "         del batch\n",
    "         gc.collect()\n",
    "        \n",
    "# Method for concatenating all batches\n",
    "def concatenate_batches(name_file):\n",
    "    file= param.save_in + '/' + name_file\n",
    "    path=Path(file)\n",
    "    files_npy=sorted(list(path.glob('*.npy')))\n",
    "    batches = []\n",
    "    for f in files_npy:\n",
    "        array = np.load(f, allow_pickle=True, mmap_mode='r') \n",
    "        batches.append(array)\n",
    "    result = np.concatenate(batches, axis=0)    \n",
    "    del batches\n",
    "    return result\n",
    "    \n",
    "# Method for split data    \n",
    "def split_data(result):\n",
    "    n_total = result.shape[0]  \n",
    "    n_train = int(n_split * n_total)\n",
    "    test = result[:n_train]\n",
    "    train = result[n_train:]\n",
    "    return train,test\n",
    "    \n",
    "#*********************************************************************************   \n",
    "\n",
    "# Create a mask\n",
    "def create_mask(u,v):\n",
    "    m,n,j,i = u.shape\n",
    "    w = np.zeros((m, n, j, i), dtype=np.float32)\n",
    "    for k in range(m):\n",
    "         w[k] = u[k] * v[k]\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d6e5ad-67b5-4315-b4e7-90767af43316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprocess_by_batches(list_of_paths[0],param.n_batch,'Geo')\\nprocess_by_batches(list_of_paths[1],param.n_batch,'Mag',False)\\nprocess_by_batches(list_of_paths[2],param.n_batch,'P',False)\\nprocess_by_batches(list_of_paths[3],param.n_batch,'Vx',False)\\nprocess_by_batches(list_of_paths[4],param.n_batch,'Vy',False)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call method for processing by batches\n",
    "# It creates 40 batches of 500 arrays each one \n",
    "\n",
    "'''\n",
    "process_by_batches(list_of_paths[0],param.n_batch,'Geo')\n",
    "process_by_batches(list_of_paths[1],param.n_batch,'Mag',False)\n",
    "process_by_batches(list_of_paths[2],param.n_batch,'P',False)\n",
    "process_by_batches(list_of_paths[3],param.n_batch,'Vx',False)\n",
    "process_by_batches(list_of_paths[4],param.n_batch,'Vy',False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0659b927-6932-4feb-9e64-8b11e20108b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call method  for concatenating all 40 batches in one array of 20000 samples\n",
    "\n",
    "geo = concatenate_batches('Geo')\n",
    "mag = concatenate_batches('Mag')\n",
    "P =  concatenate_batches('P')\n",
    "Vx = concatenate_batches('Vx')\n",
    "Vy = concatenate_batches('Vy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ee87f7b-8d4b-4331-918b-469a5a2d3a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 128, 256, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c63d5c17-e80c-43eb-9f91-0e7e8ce4d726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data in 80 % for training and 20 % for testing\n",
    "geo_train, geo_test = split_data(geo)\n",
    "mag_train, mag_test = split_data(mag)\n",
    "p_train, p_test = split_data(P)\n",
    "vx_train, vx_test = split_data(Vx)\n",
    "vy_train, vy_test = split_data(Vy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4ad6828-3907-4817-b6c2-1e7ee283efcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 128, 256, 1) and (4000, 128, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# Showing the shape of training data and testing\n",
    "print(f'{geo_train.shape} and {geo_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02a0f5e1-1763-4a1e-b618-0addc32c7996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmag_masked_train = create_mask(geo_train,mag_train)\\nmag_masked_test  = create_mask(geo_test,mag_test)\\nvy_masked_test =  create_mask(geo_test,vy_test)\\np_masked_train = create_mask(geo_train,p_train)\\np_masked_test =  create_mask(geo_test,p_test)\\nvx_masked_train = create_mask(geo_train,vx_train)\\nvx_masked_test =  create_mask(geo_test,vx_test)\\nvy_masked_train = create_mask(geo_train,vy_train)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Masking\n",
    "\n",
    "'''\n",
    "mag_masked_train = create_mask(geo_train,mag_train)\n",
    "mag_masked_test  = create_mask(geo_test,mag_test)\n",
    "vy_masked_test =  create_mask(geo_test,vy_test)\n",
    "p_masked_train = create_mask(geo_train,p_train)\n",
    "p_masked_test =  create_mask(geo_test,p_test)\n",
    "vx_masked_train = create_mask(geo_train,vx_train)\n",
    "vx_masked_test =  create_mask(geo_test,vx_test)\n",
    "vy_masked_train = create_mask(geo_train,vy_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8214715e-5650-45f4-82cd-594d753aa18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(m, n, j, i)=geo_train.shape\n",
    "mag_masked_train = np.zeros((m, n, j, i), dtype=np.float32)\n",
    "p_masked_train = np.zeros((m, n, j, i), dtype=np.float32)\n",
    "vx_masked_train = np.zeros((m, n, j, i), dtype=np.float32)\n",
    "vy_masked_train = np.zeros((m, n, j, i), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ffa751d-19eb-4672-912c-f60d9911f0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 128, 256, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mag_masked_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abef3640-af19-4472-8798-aafbbab87635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 128, 256, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e58cf1f-f372-4477-adaa-353c37cc9e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 128, 256, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vy_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fba8f96-0b5a-4fb0-9786-5e2bf082d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(m):\n",
    "    mag_masked_train[k] = geo_train[k] * mag_train[k]\n",
    "del mag_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2c4db5f-3102-4eb7-a2f0-833779d58159",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(m):\n",
    "    p_masked_train[k] = geo_train[k] * p_train[k]\n",
    "del p_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9fe101f-79ee-499f-8ff1-39ff84f85b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(m):\n",
    "    vx_masked_train[k] = geo_train[k] * vx_train[k]\n",
    "del vx_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a93149-adfa-446c-b4a6-b225321cd900",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(m):\n",
    "    vy_masked_train[k] = geo_train[k] * vy_train[k]\n",
    "del vy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c480832-2155-47d6-84dd-4b38a2764d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor of four channels\n",
    "data_merged_train = np.concatenate((mag_masked_train, p_masked_train, vx_masked_train, vy_masked_train), axis=-1)\n",
    "data_merged_tests = np.concatenate((mag_masked_test,p_masked_test,vx_masked_test, vy_masked_test), axis=-1)\n",
    "\n",
    "# print dataset values\n",
    "print(data_merged_train.shape)\n",
    "print(data_merged_tests.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d070e9f1-d4e4-45be-b335-210f8a7b43a5",
   "metadata": {},
   "source": [
    "#### 4.3 Visualizing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83beeb4e-a9cb-4587-8df0-c183747a67cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img1,img2,img3,img4,title=None,opt=None,prediction=None):\n",
    "    if opt==None and prediction==None:\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 5), sharey=True)\n",
    "        axes[0, 0].set_xticks([]);axes[0, 0].set_yticks([]);\n",
    "        axes[1, 0].set_xticks([]); axes[1, 0].set_yticks([]);\n",
    "        axes[0, 1].set_xticks([]); axes[0, 1].set_yticks([]);\n",
    "        axes[1, 1].set_xticks([]); axes[1, 1].set_yticks([]);\n",
    "        \n",
    "        axes[0, 0].imshow(img1,origin='upper',cmap='gray')\n",
    "        axes[0, 0].set_title('Input',fontsize=14)\n",
    "        axes[0, 0].set_ylabel('Geometry',fontsize=14)\n",
    "\n",
    "        axes[0, 1].imshow(img2,origin='upper',cmap='gray')\n",
    "        axes[0, 1].set_title('Output-Magnitude',fontsize=14)\n",
    "        axes[0, 1].set_ylabel('V',fontsize=14)\n",
    "\n",
    "        axes[1, 0].imshow(img3,origin='upper',cmap='gray')\n",
    "        axes[1, 0].set_title('Output x-velocity',fontsize=14)\n",
    "        axes[1, 0].set_ylabel('Vx',fontsize=14)\n",
    "\n",
    "        axes[1, 1].imshow(img4,origin='upper',cmap='gray')\n",
    "        axes[1, 1].set_title('Output-Pression',fontsize=14)\n",
    "        axes[1, 1].set_ylabel('P',fontsize=14)\n",
    "\n",
    "        if title is not None: fig.suptitle(title)\n",
    "    \n",
    "    else:\n",
    "        fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(16, 5), sharey=True)\n",
    "        ax1.set_xticks([]); ax1.set_yticks([]);\n",
    "        ax2.set_xticks([]); ax2.set_yticks([]);\n",
    "        ax1.imshow(a1,origin='upper',cmap='gray')\n",
    "        ax1.set_title('Real',fontsize=14)\n",
    "        #ax1.set_xlabel('Geometry')\n",
    "        ax1.set_ylabel('u',fontsize=14)\n",
    "        ax2.imshow(a2,origin='upper',cmap='gray')\n",
    "        ax2.set_title('Predicted',fontsize=14)\n",
    "        #ax2.set_xlabel('u')\n",
    "        ax2.set_ylabel(prediction,fontsize=16)\n",
    "        if title is not None: fig.suptitle(title)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e42c11-036e-4df1-b0cf-1b60e5da84b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_random=random.sample(range(1, geo_train.shape[0]), 1)\n",
    "show_image(geo_train[img_random[0]],mag_train[img_random[0]],\n",
    "           vx_train[img_random[0]],p_train[img_random[0]],\n",
    "           title=f\"Training data sample N°{img_random[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140e2285-e5b3-43d7-954c-17db152a70f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_random=random.sample(range(1, geo_train.shape[0]), 1)\n",
    "show_image(geo_train[img_random[0]],mag_masked_train[img_random[0]],\n",
    "           vx_masked_train[img_random[0]],p_masked_train[img_random[0]],\n",
    "           title=f\"Training data sample N°{img_random[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2266453d-dde0-4340-98d7-1d78d4ed695a",
   "metadata": {},
   "source": [
    "### 5. Hiperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f3bb73-602d-4df3-9b66-43a8eace3932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print hiperparameters\n",
    "num_classes =param.num_classes\n",
    "num_epochs =param.num_epochs\n",
    "batch_size=param.batch_size\n",
    "patience=param.patience\n",
    "LR=param.LR\n",
    "print(f'Classes= {num_classes},\\n Epochs = {num_epochs},\\n batches = {batch_size},\\n lr = {LR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e4d563-42d9-4855-8c6a-dad31a3c5d0f",
   "metadata": {},
   "source": [
    "### 6. Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169c6842-9425-4f0c-8731-2e0d6cb1975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "image_input = Input((h, w, param.channel))\n",
    "\n",
    "# 64 3x3 convolutions followed by a batchnormalization and max pool\n",
    "conv1 = Conv2D(64, (3, 3), padding='same')(image_input)\n",
    "conv1= BatchNormalization()(conv1)\n",
    "conv1 = Activation(\"relu\")(conv1)\n",
    "conv1 = Conv2D(64, (3, 3), padding='same')(conv1)\n",
    "conv1= BatchNormalization()(conv1)\n",
    "conv1 = Activation(\"relu\")(conv1)\n",
    "pool1=MaxPooling2D((2,2))(conv1)\n",
    "\n",
    "# 128 3x3 convolutions followed by a batchnormalization and max pool\n",
    "conv2 = Conv2D(128, (3, 3), padding='same')(pool1)\n",
    "conv2= BatchNormalization()(conv2)\n",
    "conv2 = Activation(\"relu\")(conv2)\n",
    "conv2 = Conv2D(128, (3, 3), padding='same')(conv2)\n",
    "conv2= BatchNormalization()(conv2)\n",
    "conv2 = Activation(\"relu\")(conv2)\n",
    "pool2=MaxPooling2D((2,2))(conv1)\n",
    "\n",
    "# 256 3x3 convolutions followed by a batchnormalization and max pool\n",
    "conv3 = Conv2D(256, (3, 3), padding='same')(pool2)\n",
    "conv3= BatchNormalization()(conv3)\n",
    "conv3 = Activation(\"relu\")(conv3)\n",
    "conv3 = Conv2D(256, (3, 3), padding='same')(conv3)\n",
    "conv3= BatchNormalization()(conv3)\n",
    "conv3 = Activation(\"relu\")(conv3)\n",
    "pool3=MaxPooling2D((2,2))(conv3)\n",
    "\n",
    "# 512 3x3 convolutions followed by a batchnormalization and max pool\n",
    "conv4 = Conv2D(512, (3, 3), padding='same')(pool3)\n",
    "conv4= BatchNormalization()(conv4)\n",
    "conv4 = Activation(\"relu\")(conv4)\n",
    "conv4 = Conv2D(512, (3, 3), padding='same')(conv4)\n",
    "conv4= BatchNormalization()(conv4)\n",
    "conv4= Activation(\"relu\")(conv4)\n",
    "pool4=MaxPooling2D((2,2))(conv4)\n",
    "\n",
    "# 1024 Bottleneck  3x3 convolutions\n",
    "conv5 = Conv2D(1024, (3,3), activation='relu', padding='same')(pool4)\n",
    "conv5 = Conv2D(1024, (3,3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "# 512 3x3 transpose convolution and concate\n",
    "conv6=Conv2DTranspose(512,(2,2),strides=(2, 2),padding=\"same\")(conv5) # remark: if it's used padding=valid, apply copy and crop the skip features\n",
    "up6=concatenate([conv6,conv4])\n",
    "conv6=Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(up6)\n",
    "conv6=Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(conv6)\n",
    "\n",
    "# 216 3x3 transpose convolution and concate\n",
    "conv7=Conv2DTranspose(216,(2,2),strides=(2, 2),padding=\"same\")(conv6) \n",
    "up7=concatenate([conv7,conv3])\n",
    "conv7=Conv2D(216, (3, 3), activation=\"relu\", padding=\"same\")(up7)\n",
    "conv7=Conv2D(216, (3, 3), activation=\"relu\", padding=\"same\")(conv7)\n",
    "\n",
    "# 128 3x3 transpose convolution and concate\n",
    "conv8=Conv2DTranspose(128,(2,2),strides=(2, 2),padding=\"same\")(conv7) \n",
    "up8=concatenate([conv8,conv3])\n",
    "conv8=Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(up8)\n",
    "conv8=Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(conv8)\n",
    "\n",
    "# 64 3x3 transpose convolution and concate\n",
    "conv9=Conv2DTranspose(64,(2,2),strides=(2, 2),padding=\"same\")(conv8) \n",
    "up9=concatenate([conv9,conv2])\n",
    "conv9=Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(up9)\n",
    "conv9=Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(conv9)\n",
    "\n",
    "# final 1x1 convolutions to get to the correct depth dim (num_classes=4 for v, v-x, v-y, p)\n",
    "output = Conv2D(num_classes, (1, 1), activation=\"relu\", padding=\"same\")(conv9)\n",
    "\n",
    "output = image_input * output\n",
    "\n",
    "# Contrut  model\n",
    "model = models.Model(image_input, output, name=\"U-Net\")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880ecfea-1f71-439d-aecc-9886fca6d7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stops the training if validation loss doesn't improve after a given patience\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "\n",
    "# compile the model with loss and optimizer\n",
    "optimizer = tf.keras.optimizers.RMSprop(LR) \n",
    "model.compile(optimizer=optimizer,\n",
    "              loss = tf.keras.losses.MeanSquaredError(),\n",
    "              metrics =[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "# Plot the resulting model architecture\n",
    "tf.keras.utils.plot_model(model, to_file=\"//home/ppgi/Trabajo/Codigos_generate_data/DLCODES-VER-5/Result_01/U_Net.png\")\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"/home/ppgi/Trabajo/Codigos_generate_data/DLCODES-VER-5/Result_01/Best_weights.weights.h5\",save_weights_only=True)\n",
    "\n",
    "# Train model\n",
    "model.fit(geo_train,data_merged_train,\n",
    "          batch_size=batch_size,\n",
    "    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446b543-155a-471a-987d-62f600d97669",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fitted=model.fit(self.train_data,self.train_data_sol,\n",
    "                                   batch_size=self.batch_size,\n",
    "                                   validation_split = 0.2,\n",
    "                                   # validation_data=(self.val_data, self.val_data_sol),\n",
    "                                    epochs=self.epoch,callbacks=[self.early_stopping(),checkpoint_cb])\n",
    "\n",
    "\n",
    "# train model\n",
    "model.fit(train_geometries, train_steady_flows,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(test_geometries, test_steady_flows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97a5aa3-274c-4d15-a3b9-ab9c4a31683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "'''\n",
    "def split_data(name_file):\n",
    "    file= param.save_in + '/' + name_file\n",
    "    path=Path(file)\n",
    "    files_npy=list(path.glob('*.npy'))\n",
    "    list_batchs = [np.load(f) for f in files_npy]\n",
    "    images_arrays = np.concatenate(list_batchs, axis=0) \n",
    "    x_train, x_test = train_test_split(images_arrays,test_size=n_split, shuffle=False)\n",
    "    return x_train, x_test\n",
    "'''\n",
    "'''\n",
    "(m, n, j, i)=geo_train.shape\n",
    "w = np.zeros((m, n, j, i), dtype=np.float32)\n",
    "for k in range(m):\n",
    "    w[k] = geo_train[k] * mag_train[k]\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
