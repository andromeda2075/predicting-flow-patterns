{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51e0157a-1a6a-4a13-a098-01f23adca71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import datetime\n",
    "import tensorflow                       as tf\n",
    "from tensorflow.keras.callbacks         import TensorBoard\n",
    "from tensorflow.keras.layers            import Input, Lambda, Conv2D,Dropout,MaxPooling2D,Conv2DTranspose,concatenate,BatchNormalization, Activation\n",
    "from tensorflow.keras.models            import Model\n",
    "from tensorflow.keras.optimizers        import Adam\n",
    "from keras.utils                        import plot_model\n",
    "from tensorflow.keras                   import layers, models\n",
    "from tensorflow.keras.losses            import mae\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import random, time\n",
    "\n",
    "import skimage                      as ski\n",
    "from   skimage.filters              import threshold_otsu\n",
    "from   skimage                      import io, color\n",
    "from   skimage.color                import rgb2gray\n",
    "from   skimage                      import filters\n",
    "import cv2                          as cv\n",
    "import matplotlib.pyplot            as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70a61cf8-3433-4f24-aa2e-6b29086f37f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main directory \n",
    "mainPath = \"/home/ppgi/Trabajo/Codigos_generate_data/DLCODES-VER-5\"\n",
    "\n",
    "directory= os.path.abspath(mainPath)\n",
    "\n",
    "# Add directory to sys.path\n",
    "sys.path.append(directory)\n",
    "\n",
    "# import script where parameters are defined\n",
    "import param  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96e16136-0e3c-44b5-b8be-8b572c2c5a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 => /home/ppgi/Trabajo/Codigos_generate_data/DLCODES-VER-5/Geometry\n",
      "1 => /home/ppgi/Trabajo/Codigos_generate_data/DLCODES-VER-5/Magnitude\n",
      "2 => /home/ppgi/Trabajo/Codigos_generate_data/DLCODES-VER-5/Pression\n",
      "3 => /home/ppgi/Trabajo/Codigos_generate_data/DLCODES-VER-5/U001\n",
      "4 => /home/ppgi/Trabajo/Codigos_generate_data/DLCODES-VER-5/U002\n",
      "\n",
      "Train = 0.8, Test = 0.2, Valid = 0.0\n",
      "\n",
      "Dimensions resized h = 128, w = 256\n",
      "\n",
      "Pack into 100 images\n"
     ]
    }
   ],
   "source": [
    "# Vizualizancing main directories \n",
    "list_of_paths = param.list_paths \n",
    "\n",
    "# Defining amount of train,valid,test images   \n",
    "n_train=param.n_train;    n_valid=param.n_valid;    n_test=param.n_test\n",
    "\n",
    "# Defining a number of samples\n",
    "n_sample=param.n_sample\n",
    "\n",
    "# For resizing dimentions\n",
    "h=param.img_height\n",
    "w=param.img_width\n",
    "\n",
    "#Pack them into batches (we’ll use batches of 10 images e.g.)\n",
    "BATCH_SIZE=param.pack_size \n",
    "\n",
    "'''\n",
    "Showing parameters\n",
    "'''\n",
    "for i,j in enumerate(list_of_paths):\n",
    "    print(f'{i} => {j}')\n",
    "\n",
    "print(f'\\nTrain = {n_train}, Test = {n_test}, Valid = {n_valid}\\n')\n",
    "print(f'Dimensions resized h = {h}, w = {w}\\n')\n",
    "print(f'Pack into {BATCH_SIZE} images')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf2a15bb-9ae9-45ee-93ef-dab943b70331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for reading image    \n",
    "def get_img(img_name):\n",
    "    return ski.io.imread(img_name)\n",
    "\n",
    "# method for turning to a grey or binary image \n",
    "def processing(image,option=True):\n",
    "        x = get_img(image)  \n",
    "        x = rgb2gray(x)       # It returns a grayscale image with floating point values in the range from 0 to 1\n",
    "        x =cv.resize(x,(w,h)) # Reshape image \n",
    "    \n",
    "        # Binary option otherwise gray\n",
    "        if (option):\n",
    "            x=ski.util.img_as_ubyte(x)  # Convert it back to the original data type and the data range back 0 to 255. \n",
    "                                        # It is often better to use image values represented by floating point values \n",
    "            best_value_threshold=np.round(filters.threshold_otsu(x)) #  Otsu’s method calculates an “optimal” threshold\n",
    "\n",
    "            _,x= cv.threshold(x, best_value_threshold, 255, cv.THRESH_BINARY)\n",
    "            x=x/255.\n",
    "        x=x[:, :, np.newaxis]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7156231b-8af9-45be-aaf2-71469de69162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  geo_train,geo_valid,geo_tests=split_data(list_of_paths[0],n_sample,n_train,n_valid,n_test) \n",
    "#  geo_array_train=arrays_img_processed(geo_train)\n",
    "def  process_by_batches(list_of_path,number_batch,option=True):\n",
    "    files=sorted([os.path.join(list_of_paths,fname) for fname in os.listdir(list_of_paths) if fname.endswith(\".png\")])\n",
    "    n_files=len(files)\n",
    "    for k,start in enumerate(range(0,n_files,number_batch)):\n",
    "         batch=[]\n",
    "         end = min(start + number_batch, n_files)\n",
    "         file_batches=files[start:end]\n",
    "         for img in file_batches:\n",
    "             x = processing(img,option)\n",
    "             batch.append(x)\n",
    "         np.save(f'batch_images_{k:03d}.npy',batch,allow_pickle=True)   \n",
    "         del batch\n",
    "         gc.collect()\n",
    "        \n",
    "\n",
    "           \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86ff17e-35df-4296-b315-762ed4c927e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(lista_de_batches):\n",
    "    np.save(f'batch_{i:03d}.npy', batch)\n",
    "# Busca todos los archivos .npy\n",
    "lote_files = sorted(glob.glob(\"batch_*.npy\"))\n",
    "\n",
    "# Cargar y concatenar\n",
    "lotes = [np.load(f) for f in lote_files]\n",
    "todo = np.concatenate(lotes, axis=0)  # Eje 0: une verticalmente\n",
    "\n",
    "print(\"Shape total:\", todo.shape)  \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Supongamos que `todo` es tu array (ej: imágenes)\n",
    "X_train, X_test = train_test_split(todo, test_size=0.2, random_state=42)\n",
    "\n",
    "lista_cargada = np.load('lista_de_arrays.npy', allow_pickle=True)\n",
    "\n",
    "lista_cargada = lista_cargada.tolist()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
